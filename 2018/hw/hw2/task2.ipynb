{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 14pt\">Дедлайн: 13 марта 23:59</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Машинное обучение, ФИВТ, Весна 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составлено с использованием материалов Евгения Колмакова и Юрия Кашницкого (открытый курс машинного обучения, тема 3), а также лекций по машинному обучению Евгения Соколова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall <номер_группы> <фамилия>``, к примеру -- ``ML2018_fall 596 ivanov``\n",
    "- Выполненное дз сохраните в файл ``ML2018_<фамилия>_<группа>_task<номер задания>.ipnb``, к примеру -- ``ML2018_ivanov_596_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Используются автоматические фильтры, мы не найдем ваше дз, если вы укажете тему письма в неправильном формате.\n",
    "- **PS2**: Просроченный дедлайн снижает максимальный вес задания по формуле, указнной на первом семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 0. Вопросы для самоконтроля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Перед выполнением задания убедитесь, что вы знаете ответы на этот теор.минимум\n",
    "##### Эта часть задания не оценивается, ответы можно не записывать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Что такое решающее дерево? Как по построенному дереву найти прогноз для объекта?\n",
    "2. Почему для любой выборки можно построить дерево, имеющее нулевую ошибку на ней? Приведите примеры.\n",
    "3. Почему не рекомендуется строить небинарные деревья (имеющие более двух потомков у каждой вершины)?\n",
    "4. Как устроен жадный алгоритм построения дерева?\n",
    "5. Какие критерии информативности для решения задачи классификации вы знаете?\n",
    "6. Какой смысл у критерия Джини и энтропийного критерия?\n",
    "7. Какие критерии информативности для решения задачи регрессии вы знаете?\n",
    "8. Что такое pruning (стрижка) дерева? Чем отличаются post-pruning и pre-pruning?\n",
    "9. Какие методы обработки пропущенных значений вы знаете?\n",
    "10. Как учитывать категориальные признаки в решающем дереве?\n",
    "11. Что такое mean target encoding? Почему эта техника хорошо работает для решающих деревьев?\n",
    "12. Как работает отбор признаков с помощью решающих деревьев?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Теоретические задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30% баллов за задание, оценочное время выполнения 1 час"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение можно затехать здесь или написать от руки и добавить фото в ноутбук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1 (10% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая стратегия поведения в листьях регрессионного дерева приводит к меньшему матожиданию ошибки по MSE: отвечать средним значением таргета на объектах обучающей выборки, попавших в лист, или отвечать таргетом для случайного объекта из листа (считая все объекты равновероятными)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2 (15% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критерий информативности для набора объектов $L$ вычисляется на основе того, насколько хорошо их целевые переменные предсказываются константой (при оптимальном выборе этой константы):\n",
    "$$H(R) = \\min_{c \\in Y} \\dfrac{1}{|R|} \\sum_{(x_i,y_i) \\in R} L(y_i, c),$$\n",
    "где $L(y_i, c)$- некоторая функция потерь. Соответственно, чтобы получить вид критерия при конкретной функции потерь, необходимо аналитически найти оптимальное значение константы и подставить его в формулу для $H(R)$.\n",
    "\n",
    "Выведите критерии информативности для следующих функций потерь:\n",
    "1. $L(y,c) = (y-c)^2$\n",
    "2. $L(y,c) = \\sum_{k=1}^K (c_k-[y=k])^2$\n",
    "3. $L(y,c) = -\\sum_{k=1}^K [y=k]\\log c_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подсказка**:\n",
    "должны получиться дисперия, критерий Джини и энтропийный критерий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3 (5% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишите оценку сложности построения одного решающего дерева в зависимости от размера обучающей выборки $l$, числа признаков $d$, максимальной глубины дерева $D$. В качестве предикатов используются пороговые функции $[x_j>t]$. При выборе предиката в каждой вершине перебираются все признаки, а в качестве порогов рассматриваются величины $t$, равные значения этого признака на объектах, попавших в текущую вершину. Считайте сложность вычисления критерия информативноси константной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Визуализация решающих деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20% баллов за задание, оценочное время выполнения 30 минут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала нужно поставить GraphViz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- На macOS:\n",
    "    - sudo pip install pydotplus\n",
    "    - brew install graphviz\n",
    "- Linux должно работать то же самое с заменой brew на sudo apt-get\n",
    "    - sudo pip install pydotplus\n",
    "    - sudo apt-get install graphviz\n",
    "- Windows\n",
    "    - Установить GraphViz отсюда: http://www.graphviz.org/Download_windows.php\n",
    "    - Добавить путь к папке bin в PATH (например, \"C:\\Programs\\Graphviz2.38\\bin\")\n",
    "    - pip install pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте решающее дерево из sklearn на датасете Car Evaluation Dataset (https://archive.ics.uci.edu/ml/datasets/car+evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте получившееся дерево с помощью GraphViz (следующая функция может помочь):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display #needed to render in notebook\n",
    "import StringIO, pydot  #needed to convert dot format to png\n",
    "from sklearn import tree\n",
    "\n",
    "def draw_decision_tree(clf, column_names):\n",
    "    dot_data = StringIO.StringIO() \n",
    "    tree.export_graphviz(clf, out_file=dot_data, feature_names=column_names) \n",
    "    graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "    a = IPython.display.Image(graph.create_png())\n",
    "    IPython.display.display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите, как меняется картинка для различных значений структурных параметров (варьируйте параметры max_depth, criterion, min_samples_leaf, max_features). Убедитесь, что увеличение глубины дерева и уменьшение количества объектов в листьях способствует гибкости модели и, как следствие, переобучению (что соответствует интуитивным соображениям о структуре дерева)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Реализация алгоритма построения дерева решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 50% баллов за задание, оценочное время выполнения 2-3 часа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем заранее `random_state` (a.k.a. random seed). Это должно повысить вероятность полной воспроизводимости результатов, впрочем, замечено, что тем не менее небольшие флуктуации возможны (например, качества прогнозов дерева, которое мы сейчас вырастим) в случае разных ОС."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Необходимо реализовать класс `DecisionTree`**\n",
    "\n",
    "**Спецификация:**\n",
    "- класс наследуется от `sklearn.BaseEstimator`;\n",
    "- конструктор содержит следующие параметры: \n",
    "    `max_depth` - максимальная глубина дерева (по умолчанию - `numpy.inf`); \n",
    "    `min_samples_split` - минимальное число объектов в вершине, при котором происходит её разбиение (по умолчанию - 2); \n",
    "    `criterion` - критерий разбиения (для классификации - 'gini' или 'entropy', для регрессии - 'variance' или 'mad_median'; \n",
    "    по умолчанию - 'gini');\n",
    "    \n",
    "    Функционал, значение которого максимизируется для поиска оптимального разбиения в данной вершине имеет вид\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$\n",
    "    где $X$ - выборка, находящаяся в текущей вершине, $X_l$ и $X_r$ - разбиение выборки $X$ на две части \n",
    "    по предикату $[x_j < t]$, а $F(X)$ -критерий разбиения.\n",
    "    \n",
    "    1. Для классификации: пусть $p_i$ - доля объектов $i$-го класса в выборке $X$.\n",
    "    \n",
    "        - 'gini': Неопределенность Джини $F(X) = 1 -\\sum_{i = 1}^K p_i^2$.\n",
    "    \n",
    "        - 'entropy': Энтропия $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$.\n",
    "    \n",
    "    2. Для регрессии: $y_j = y(x_j)$ - ответ на объекте $x_j$, $y = (y_1, \\dots, y_{|X|})$ - вектор ответов.\n",
    "    \n",
    "        - 'variance': Дисперсия (среднее квадратичное отклонение от среднего) $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j - \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2$\n",
    "    \n",
    "        - 'mad_median': Среднее отклонение от медианы $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}|y_j - \\mathrm{med}(y)|$\n",
    "    \n",
    "- класс имеет методы `fit`, `predict` и `predict_proba`;\n",
    "- метод `fit` принимает матрицу объектов `X` и вектор ответов `y` (объекты `numpy.ndarray`) и возвращает экземпляр класса\n",
    "    `DecisionTree`, представляющий собой решающее дерево, обученное по выборке `(X, y)` с учётом заданных в конструкторе параметров; \n",
    "- метод `predict_proba` принимает матрицу объектов `X` и возвращает матрицу `P` размера `X.shape[0] x K`, где `K` - число классов, такую что $p_{ij}$ есть вероятность принадлежности объекта, заданного $i$-ой строкой матрицы X к классу $j \\in \\{1, \\dots, K\\}$.\n",
    "- метод `predict` принимает матрицу объектов и возвращает вектор предсказанных ответов; в случае классификации - это \n",
    "    наиболее многочисленный класс в листе, в который попал объект, а в случае регрессии - среднее значение ответов по \n",
    "    всем объектам этого листа;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Советы по реализации:**\n",
    "\n",
    "- Обучение дерева можно реализовать простым жадным рекурсивным алгоритмом: каждый раз выбирать наилучшее разбиение (номер признака и порог по нему).\n",
    "- Если возможных порогов для разбиения будет слишком много, выбор наилучшего разбиения окажется вычислительно очень громоздкой задачей. Можно ограничить множество порогов любым удобным способом (например, посчитать квантили значений каждого признака или просто взяв случайный набор порогов).\n",
    "- Лучше не подсматривать решение в готовых нагугленных вариантах. От вас требуется сделать всего лишь максимально простую реализацию того, как строится и применяется решающее дерево, а не применимую на практике универсальную библиотеку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация (30% баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):  \n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "def gini(y):\n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "def variance(y):\n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "def mad_median(y):\n",
    "    # Ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, \n",
    "                 criterion='gini', debug=False):\n",
    "        # Ваш код здесь\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Ваш код здесь\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Ваш код здесь\n",
    "        pass\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        # Ваш код здесь\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование реализованного алгоритма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация (10% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `load_digits` загрузите датасет `digits`. Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=42`. Попробуйте обучить неглубокие решающие деревья и убедитесь, что критерии gini и entropy дают разные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью 5-кратной кросс-валидации (`GridSearchCV`) подберите оптимальное значение параметров `max_depth` и `criterion`. Для параметра `max_depth` используйте диапазон значений - range(3, 11), а для criterion - {'gini', 'entropy'}. Критерий качества `scoring`='accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики средних значений критерия качества `accuracy` для критериев `gini` и `entropy` в зависимости от `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируйте полученные графики. Чему равны найденные оптимальные значения параметров max_depth и criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя найденные оптимальные значения max_depth и criterion, обучите решающее дерево на X_train, y_train и вычислите вероятности принадлежности к классам для X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полученной матрицы вычислите усредненные по всем объектам из `X_test` значения вероятностей принадлежности к классам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чему примерно равна максимальная вероятность в полученном векторе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регрессия (10% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `load_boston` загрузите датасет `boston`. Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=42`. Попробуйте обучить неглубокие регрессионные деревья и убедитесь, что критерии `variance` и `mad_median` дают разные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью 5-кратной кросс-валидации подберите оптимальное значение параметров `max_depth` и `criterion`. Для параметра `max_depth` используйте диапазон значений - `range(2, 9)`, а для `criterion` - {'variance', 'mad_median'}. Критерий качества `scoring`='neg_mean_squared_error'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте графики средних значений критерия качества `neg_mean_squared_error` для критериев `variance` и `mad_median` в зависимости от `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Проанализируйте полученные графики. Чему равны найденные оптимальные значения параметров max_depth и criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
